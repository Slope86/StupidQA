{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "初始化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c99EvWo1s9-x"
      },
      "outputs": [],
      "source": [
        "# 掛載雲端\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 環境初始化 (大約三至五分鐘)\n",
        "! wget -O init_env.sh https://www.dropbox.com/s/4jvf5hg8paip699/init_env%20spark%203.1.1.sh?dl=0 && \\\n",
        "bash init_env.sh\n",
        "\n",
        "import os, sys\n",
        "os.environ['SPARK_HOME'] = \"/usr/local/spark\"\n",
        "os.environ['PYSPARK_PYTHON'] = \"/usr/local/bin/python\"\n",
        "sys.path.append(\"/usr/local/spark/python/\")\n",
        "sys.path.append(\"/usr/local/spark/python/lib/pyspark.zip\")\n",
        "sys.path.append(\"/usr/local/spark/python/lib/py4j-0.10.9-src.zip\")\n",
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "sc = SparkContext()\n",
        "\n",
        "#my env\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "spark = SparkSession(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wiki資料讀取"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVokn46x7H6Y"
      },
      "outputs": [],
      "source": [
        "wiki_rdd = sc.textFile(\"drive/My Drive/wiki.plain.text.line.spark.rdd.format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "詞頻計算，將結果存到word_count.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vTXiAesskzr"
      },
      "outputs": [],
      "source": [
        "word_counts_RDD = wiki_rdd\\\n",
        "          .flatMap(lambda line: line.split(\" \"))\\\n",
        "          .filter(lambda word: len(word)>1 and not word.isnumeric() )\\\n",
        "          .map(lambda word: (word, 1))\\\n",
        "          .reduceByKey(lambda a, b: a + b)\\\n",
        "          .sortBy(lambda x:x[1], ascending=False)\n",
        "          \n",
        "word_count_DF = word_counts_RDD.toDF((\"word\", \"count\")).toPandas()  \n",
        "word_count_DF.to_csv(\"drive/My Drive/word_count.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "整理【關鍵字與出現此字的文章列表】，將結果存到word_article.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2leKwuNom5d"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "from typing import List\n",
        "\n",
        "def mark_and_split(article: str) -> List[tuple]:\n",
        "  article_split = article.split()\n",
        "  id = article_split[0]\n",
        "  content  = article_split[1:]\n",
        "  return [(word, id) for word in content]\n",
        "\n",
        "def To_list_like_string(input: Iterable[str]) -> str:\n",
        "  \"\"\" \n",
        "  Turn input Iterable[str] into a【no repeated element】list,\n",
        "  than turn the list into a【list expression】string.\n",
        "\n",
        "  Example_input : list[str] = ['100', '101', '104', '101']\n",
        "  Example_output : str = '[100,101,104]'\n",
        "  \"\"\"\n",
        "  input = list(set(input))\n",
        "  output = ['[']\n",
        "  for i in input:\n",
        "    output.append(i)\n",
        "    output.append(',')\n",
        "  output[-1] = ']'\n",
        "  return ''.join(output)\n",
        "\n",
        "word_group_RDD = wiki_rdd\\\n",
        "          .flatMap(mark_and_split)\\\n",
        "          .filter(lambda pair: len(pair[0])>1)\\\n",
        "          .groupByKey()\\\n",
        "          .map(lambda pair: (pair[0],To_list_like_string(pair[1])))\n",
        "\n",
        "word_group_DF = word_group_RDD.toDF((\"word\", \"id\"))\n",
        "word_group_DF.coalesce(1).write.csv(\"drive/My Drive/word_article.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT6GXSgr2Cd0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
